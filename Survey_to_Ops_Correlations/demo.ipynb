{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey to Operational Metrics - Demo with Synthetic Data\n",
    "\n",
    "This notebook generates synthetic customer survey and operational data to demonstrate correlation analysis techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Parameters\n",
    "\n",
    "Define configurable parameters for all synthetic data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey configuration\n",
    "SURVEY_CONFIG = {\n",
    "    'start_date': '2020-01-01',\n",
    "    'end_date': '2023-12-31',\n",
    "    'avg_responses_per_month': 2000,\n",
    "    'response_std': 200,  # Standard deviation in monthly responses\n",
    "    'total_customer_pool': 50000,  # Total unique customers\n",
    "    'metrics': {\n",
    "        'overall_satisfaction': {'min': 1, 'max': 10, 'mean': 7.0, 'std': 2.0},\n",
    "        'product_quality': {'min': 1, 'max': 15, 'mean': 10.5, 'std': 3.0},\n",
    "        'customer_service': {'min': 1, 'max': 15, 'mean': 11.0, 'std': 2.8},\n",
    "        'ease_of_use': {'min': 1, 'max': 15, 'mean': 10.0, 'std': 3.2},\n",
    "        'value_for_money': {'min': 1, 'max': 15, 'mean': 9.5, 'std': 3.5},\n",
    "        'likelihood_to_recommend': {'min': 1, 'max': 15, 'mean': 10.2, 'std': 3.3}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Operational metrics configuration\n",
    "OPS_CONFIG = {\n",
    "    'num_calls': {\n",
    "        'pct_no_calls': 0.65,  # 65% of customers made no calls\n",
    "        'pct_1_call': 0.20,     # 20% made 1 call\n",
    "        'pct_2_5_calls': 0.12,  # 12% made 2-5 calls\n",
    "        'pct_6_plus_calls': 0.03,  # 3% made 6+ calls\n",
    "        'max_calls_heavy_users': 25  # Max calls for heavy users\n",
    "    },\n",
    "    'login_frequency': {\n",
    "        'mean': 15.0,  # Average logins per month\n",
    "        'std': 10.0,\n",
    "        'min': 0,\n",
    "        'max': 90  # ~3 per day max\n",
    "    },\n",
    "    'feature_usage_count': {\n",
    "        'mean': 25.0,  # Average feature interactions per month\n",
    "        'std': 15.0,\n",
    "        'min': 0,\n",
    "        'max': 200\n",
    "    },\n",
    "    'session_duration_minutes': {\n",
    "        'mean': 120.0,  # Total minutes spent per month\n",
    "        'std': 80.0,\n",
    "        'min': 0,\n",
    "        'max': 600  # 10 hours max\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Survey Response Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_survey_data(config):\n",
    "    \"\"\"\n",
    "    Generate synthetic survey response data.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with customer_id, survey_date, and response metrics\n",
    "    \"\"\"\n",
    "    start = pd.to_datetime(config['start_date'])\n",
    "    end = pd.to_datetime(config['end_date'])\n",
    "    \n",
    "    # Generate date range (monthly)\n",
    "    months = pd.date_range(start=start, end=end, freq='MS')\n",
    "    \n",
    "    all_responses = []\n",
    "    \n",
    "    for month in months:\n",
    "        # Determine number of responses this month\n",
    "        n_responses = int(np.random.normal(\n",
    "            config['avg_responses_per_month'], \n",
    "            config['response_std']\n",
    "        ))\n",
    "        n_responses = max(100, n_responses)  # At least 100 responses\n",
    "        \n",
    "        # Randomly sample customer IDs\n",
    "        customer_ids = np.random.choice(\n",
    "            range(1, config['total_customer_pool'] + 1),\n",
    "            size=n_responses,\n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Generate random dates within the month\n",
    "        days_in_month = (month + pd.DateOffset(months=1) - timedelta(days=1)).day\n",
    "        survey_dates = [month + timedelta(days=np.random.randint(0, days_in_month)) \n",
    "                       for _ in range(n_responses)]\n",
    "        \n",
    "        month_data = {'customer_id': customer_ids, 'survey_date': survey_dates}\n",
    "        \n",
    "        # Generate responses for each metric\n",
    "        for metric_name, metric_config in config['metrics'].items():\n",
    "            responses = np.random.normal(\n",
    "                metric_config['mean'],\n",
    "                metric_config['std'],\n",
    "                n_responses\n",
    "            )\n",
    "            # Clip to valid range and round\n",
    "            responses = np.clip(responses, metric_config['min'], metric_config['max'])\n",
    "            responses = np.round(responses).astype(int)\n",
    "            month_data[metric_name] = responses\n",
    "        \n",
    "        all_responses.append(pd.DataFrame(month_data))\n",
    "    \n",
    "    df = pd.concat(all_responses, ignore_index=True)\n",
    "    df = df.sort_values('survey_date').reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the data\n",
    "survey_df = generate_survey_data(SURVEY_CONFIG)\n",
    "\n",
    "print(f\"Generated {len(survey_df):,} survey responses\")\n",
    "print(f\"Date range: {survey_df['survey_date'].min()} to {survey_df['survey_date'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "survey_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Operational Metrics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_num_calls(customer_ids, config):\n    \"\"\"\n    Generate num_calls based on configured distribution.\n    \"\"\"\n    n = len(customer_ids)\n    calls = np.zeros(n, dtype=int)\n    \n    # Assign call counts based on percentages\n    idx = 0\n    \n    # No calls\n    n_no_calls = int(n * config['pct_no_calls'])\n    calls[idx:idx + n_no_calls] = 0\n    idx += n_no_calls\n    \n    # 1 call\n    n_1_call = int(n * config['pct_1_call'])\n    calls[idx:idx + n_1_call] = 1\n    idx += n_1_call\n    \n    # 2-5 calls\n    n_2_5_calls = int(n * config['pct_2_5_calls'])\n    calls[idx:idx + n_2_5_calls] = np.random.randint(2, 6, n_2_5_calls)\n    idx += n_2_5_calls\n    \n    # 6+ calls (heavy users)\n    n_6_plus = n - idx\n    calls[idx:] = np.random.randint(6, config['max_calls_heavy_users'] + 1, n_6_plus)\n    \n    # Shuffle to randomize\n    np.random.shuffle(calls)\n    \n    return calls\n\n\ndef generate_continuous_metric(customer_ids, config):\n    \"\"\"\n    Generate a continuous metric with normal distribution.\n    \"\"\"\n    n = len(customer_ids)\n    values = np.random.normal(config['mean'], config['std'], n)\n    values = np.clip(values, config['min'], config['max'])\n    return np.round(values, 1)\n\n\ndef generate_operational_data_with_correlations(survey_df, ops_config):\n    \"\"\"\n    Generate operational metrics with realistic correlations to survey responses.\n    \n    Key correlations:\n    - More calls -> Lower customer_service score (negative)\n    - Higher usage (logins, features, duration) -> Higher satisfaction (positive)\n    - These create realistic patterns for analysis\n    \n    Returns:\n        DataFrame with customer_id, survey_date, and operational metrics\n    \"\"\"\n    n = len(survey_df)\n    customer_ids = survey_df['customer_id'].values\n    survey_dates = survey_df['survey_date'].values\n    \n    # Generate base operational metrics\n    base_calls = generate_num_calls(customer_ids, ops_config['num_calls'])\n    base_logins = generate_continuous_metric(customer_ids, ops_config['login_frequency'])\n    base_features = generate_continuous_metric(customer_ids, ops_config['feature_usage_count'])\n    base_duration = generate_continuous_metric(customer_ids, ops_config['session_duration_minutes'])\n    \n    # Create correlated survey responses\n    # Higher calls -> lower customer service (negative correlation ~-0.4)\n    customer_service = survey_df['customer_service'].values\n    customer_service_adjusted = customer_service - (base_calls * 0.3) + np.random.normal(0, 1.5, n)\n    customer_service_adjusted = np.clip(customer_service_adjusted, 1, 15).round().astype(int)\n    \n    # Higher usage -> higher satisfaction (positive correlations ~0.3-0.5)\n    overall_sat = survey_df['overall_satisfaction'].values\n    usage_effect = (base_logins / 50 + base_features / 100 + base_duration / 300)\n    overall_sat_adjusted = overall_sat + usage_effect + np.random.normal(0, 1.2, n)\n    overall_sat_adjusted = np.clip(overall_sat_adjusted, 1, 10).round().astype(int)\n    \n    # Ease of use influenced by feature usage (moderate positive ~0.3)\n    ease_of_use = survey_df['ease_of_use'].values\n    ease_adjusted = ease_of_use + (base_features / 80) + np.random.normal(0, 2, n)\n    ease_adjusted = np.clip(ease_adjusted, 1, 15).round().astype(int)\n    \n    ops_data = {\n        'customer_id': customer_ids,\n        'survey_date': survey_dates,\n        'num_calls': base_calls,\n        'login_frequency': base_logins,\n        'feature_usage_count': base_features,\n        'session_duration_minutes': base_duration\n    }\n    \n    # Update survey responses with correlated versions\n    survey_updates = {\n        'overall_satisfaction': overall_sat_adjusted,\n        'customer_service': customer_service_adjusted,\n        'ease_of_use': ease_adjusted\n    }\n    \n    return pd.DataFrame(ops_data), survey_updates\n\n\n# Generate operational data with correlations\nops_df, survey_updates = generate_operational_data_with_correlations(survey_df, OPS_CONFIG)\n\n# Update survey responses with correlated versions\nfor col, values in survey_updates.items():\n    survey_df[col] = values\n\nprint(f\"Generated operational metrics for {len(ops_df):,} customer-survey pairs\")\nprint(f\"Added realistic correlations:\")\nprint(f\"  - num_calls negatively affects customer_service\")\nprint(f\"  - Higher usage (logins, features, duration) positively affects overall_satisfaction\")\nprint(f\"  - feature_usage_count positively affects ease_of_use\")\nprint(f\"\\nOperational metrics summary:\")\nops_df.describe()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combine Survey and Operational Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge survey responses with operational metrics\n",
    "combined_df = survey_df.merge(\n",
    "    ops_df,\n",
    "    on=['customer_id', 'survey_date'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(combined_df.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Data Exploration\n\n### 5.1 Survey Metrics Distribution"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey metrics distribution\n",
    "survey_metrics = ['overall_satisfaction', 'product_quality', 'customer_service', \n",
    "                 'ease_of_use', 'value_for_money', 'likelihood_to_recommend']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(survey_metrics):\n",
    "    axes[i].hist(combined_df[metric], bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(metric.replace('_', ' ').title())\n",
    "    axes[i].set_xlabel('Score')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Survey Metrics Distributions', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 5.2 Operational Metrics Distribution",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Define metrics for correlation analysis\nsurvey_metrics = ['overall_satisfaction', 'product_quality', 'customer_service', \n                 'ease_of_use', 'value_for_money', 'likelihood_to_recommend']\nops_metrics = ['num_calls', 'login_frequency', 'feature_usage_count', 'session_duration_minutes']\nmetrics_for_corr = survey_metrics + ops_metrics\n\n# Correlation heatmap (individual level)\ncorr_matrix = combined_df[metrics_for_corr].corr()\n\nplt.figure(figsize=(14, 10))\nsns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n            center=0, square=True, linewidths=1)\nplt.title('Correlation Matrix: Survey and Operational Metrics (Individual Level)', fontsize=14, pad=20)\nplt.tight_layout()\nplt.show()",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate monthly aggregates\ncombined_df['year_month'] = combined_df['survey_date'].dt.to_period('M')\n\nmonthly_agg = combined_df.groupby('year_month')[metrics_for_corr].mean().reset_index()\nmonthly_agg['year_month'] = monthly_agg['year_month'].astype(str)\n\nprint(f\"Aggregated to {len(monthly_agg)} months\")\nprint(f\"\\nMonthly aggregated data (first 5 months):\")\nprint(monthly_agg.head())\n\n# Calculate correlation on monthly aggregates\nmonthly_corr_matrix = monthly_agg[metrics_for_corr].corr()\n\nplt.figure(figsize=(14, 10))\nsns.heatmap(monthly_corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n            center=0, square=True, linewidths=1)\nplt.title('Correlation Matrix: Monthly Aggregated Metrics', fontsize=14, pad=20)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.4 Correlation Analysis (Aggregated Monthly Means)\n\nAggregate data by month and calculate correlations between monthly averages.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operational metrics distribution\n",
    "ops_metrics = ['num_calls', 'login_frequency', 'feature_usage_count', 'session_duration_minutes']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(ops_metrics):\n",
    "    axes[i].hist(combined_df[metric], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(metric.replace('_', ' ').title())\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Operational Metrics Distributions', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "metrics_for_corr = survey_metrics + ops_metrics\n",
    "corr_matrix = combined_df[metrics_for_corr].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix: Survey and Operational Metrics', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for further analysis\n",
    "combined_df.to_csv('synthetic_survey_ops_data.csv', index=False)\n",
    "print(\"Data exported to 'synthetic_survey_ops_data.csv'\")\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"Total records: {len(combined_df):,}\")\n",
    "print(f\"Date range: {combined_df['survey_date'].min()} to {combined_df['survey_date'].max()}\")\n",
    "print(f\"Unique customers: {combined_df['customer_id'].nunique():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}